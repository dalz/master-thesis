\chapter{Experience report}
\label{ch:evaluation}

Katamaran is a relatively recent research project, and while it is approaching maturity, it hasn't been extensively put to the test yet. As such we find it valuable to report our experience with Katamaran, noting what works and what needs to be improved, some insights to keep in mind to make good use of the tool, and some metrics (line count and verification time) of the final codebase.

\section{Effective design of contracts}

The final proofs presented in \cref{sec:uc-verification} are mostly trivial. Indeed, Katamaran showed itself to be very effective at proving our contracts once they were properly specified, with ``properly'' meaning a combination of multiple factors.

Firstly, the contracts have to be actually provable, or the verification will fail for obvious reasons. This \emph{will} happen during the development. Chiefly because of oversights in the specification; after all, there would be no point in verifying the ISA if we were completely sure of the absence of bugs in it. See \cref{sec:pc-mod-order} for an example of this in our \msp model.

Other times the security property doesn't hold in some edge cases (\eg in the presence of overflows or misconfigurations) which can be expected not to occur in practice; this is dealt with by strengthening the precondition. For instance we added the assumption that the lower boundary of the IPE region is less than the upper after finding out it was needed to verify \sail{read_autoincrement}.

It may happen that a contract \emph{would} be provable by pure symbolic execution (assuming no time constraints), but isn't if the executor takes advantage of other contracts we specified instead of unfolding function calls. In other words, the user's specification of an auxiliary function isn't sufficiently precise to carry out the caller's verification. In our case we had to go back and update \sail{write_register}'s contract to support the verification of \sail{read_autoincrement}. This was already discussed in \cref{sec:read-autoincrement-proof}, but in short \sail{write_register}'s original postcondition abstracted away some information about the PC that was later found to be necessary. Similar situations are bound to happen as the user tries to strike a balance between the strength of the properties (pushing \eg toward more complex and precise postconditions) and amenability to automated reasoning (simpler, more vague postconditions).

Another key requirement for a successful verification is simplicity of the target code. Symbolic execution of complex functions runs into combinatorial explosion of the state space, leading to unreasonable verification times and out-of-memory errors. The needed reduction in complexity is usually achieved by means of supporting contracts that replace the unfolding of functions; there are many examples of this in \cref{sec:uc-verification}. Sometimes a change to the model is called for, particularly when a function:
\begin{itemize}
\item Has a \usail translation so complex that Rocq has a hard time type-checking it. This is a consequence of the approach employed by \usail to ensure that a well-typed (according to Rocq's type system) \usail term represents a well-typed piece of Sail code, which is very slow with large typing contexts.
\item Performs a large number of operations itself, without delegating via function calls. Such monolithic functions lack opportunities of easing the executor's workload via supporting contracts, and must either be split up into simpler procedures or possibly enhanced with some lemma invocations that implement the less trivial reasoning steps.
\end{itemize}
The original Sail model included very complex \sail{read} and \sail{write} functions, which we had to split into one read/write function per addressing mode.

Further, the target property itself may be the cause of excessive slowdowns. If that is the case, predicates can be introduced to turn the heavier propositions into opaque objects, that are then manipulated or unpacked as needed through the use of lemmas.

Finally, the user should be aware of the way Katamaran consumes chunks. By default, it looks for a chunk in the heap with syntactically equal inputs, and generates an error (discussed in the next section) if it can't find any. The user can instead use angelic chunks, which are consumed nondeterministically by continuing the execution with each of the possible choices from the heap, until in one branch the symbolic executor can prove that the consumed chunk matched the requested one. Angelic chunks have negative performance implications, so they should be used only when strictly necessary. Additionally, angelic chunks may still fail to be consumed even if they are in the heap, if the solver isn't smart enough to match them.

\section{Debugging of verification failures}

It doesn't come as a surprise that most of the effort is spent getting the contracts into the good state described in the previous section. Katamaran provides some facilities to navigate the many verification failures that occur during this process.

We can distinguish two kinds of failures: unprovable verification conditions (VCs) and actual errors.

When an error occurs, we are left with a VC that, in the simplest case, looks like:
\[ \forall \text{variables},\; \text{path conditions} \to \texttt{error}~\text{debug record}, \]
where \(\texttt{error}~r\) is equivalent to false. The debug record contains information about the executor's state at the time the error occurred: program context (list of program variables and their types), local store (values bound to the program variables), path condition (expressions that must be true for this branch to be executed), heap, and the cause of the error. The latter may be either an assertion failure (\eg an equality in the precondition of a supporting contract is not satisfied) or a failure to consume a chunk from the heap (\eg reading from a register whose ownership was not assumed in the precondition).

If we instead end up with an unprovable VC, we can ask for such debug nodes to be inserted at arbitrary points by adding \coq{stm_debugk} statements to the \usail code. With some practice, this information can be used to nail down the source of the problem effectively.

The verification condition can be much more complex than the pattern shown above, with multiple disjunctions and conjunctions. Various times we were faced with thousands and tens of thousands of lines of verification conditions. This happens in particular when Katamaran's solver is not smart enough to prune or unify enough branches. Even though they are not too hard to inspect by hand, these verification conditions slow down the tooling (on both the Rocq/Proof General and Katamaran sides) to a crawl, if they don't cause out-of-memory crashes outright.

Katamaran's answer to this is an optional \emph{erasure} pass that transforms the \usail code into an untyped representation, which is much less expensive to handle. We used erasure on all our proofs for the significant speedup, reducing processing times from multiple minutes to a few seconds for simple functions, and from hours to minutes in the most complex.

Unfortunately, useful debugging information is lost in the process. Variables lose their names from the \usail specification, and are replaced with generated Rocq identifiers like \coq{v7}. This makes it harder to guess where an unprovable VC may have originated from. Additionally, debug nodes are replaced with \coq{False}, at which point identifying errors requires either disabling erasure (only possible for simple functions) or a lot of trial and error (\eg giving trivial preconditions to supporting contracts or commenting out parts of the code). Either way, iterating on the contract becomes slow and tedious.

\section{Translation of Sail to \usail}

\usail generation is a recent addition to Katamaran and still has some rough edges. One aspect that could be easily improved is the quality of the formatting: the backend builds \usail statements directly via their constructors instead of taking advantage of Rocq's custom notations feature. For example, the \msp \usail specification contains:
\begin{minted}{coq}
    stm_let "x"
          (ty.int)
          (stm_call signedWb (env.snoc (env.nil)
                                       (_::_)
                                       ((exp_var "w"))%exp))
          (stm_exp (((exp_var "x"))<((exp_int 0%Z))))
\end{minted}
which could be rewritten, using notations, to:
\begin{minted}{coq}
    let: "x" := call signedWb [w] in
    x < 0
\end{minted}

The backend also tends to produce long lines (the longest being 408 characters, mostly indentation and 50 closing parentheses) that are hard to work with in an editor.

Due to a combination of factors, mainly expressive blind spots in \usail and suboptimal translation, the generated model tends to be quite large. As was already remarked single excessively complex functions may cause Rocq's type checker to hang.
% , but even if that is not the case compilation time is affected negatively.

These issues can be mostly ascribed to the backend's immaturity. A more fundamental point of friction lies in the propagation of changes from Sail to \usail. During the verification process the user is expected to modify the \usail specification to include lemma invocations, and we had to make additional changes due to bugs in the generated code; as a consequence, the working copy of the \usail model is not a direct translation from Sail. If it ever becomes necessary to update the Sail specification (\eg for an extension or to fix a bug), one way to handle the change is to regenerate the \usail code, diff it against the original, and apply the resulting patch to the working copy.

This process is tedious in case of frequent iteration on the specification, especially as the translation is not stable under local changes: a small edit to the Sail source can affect the whole \usail file---particularly the names of the generated identifiers and the comments recording the original position in the source of each \usail function.

It would be helpful if the backend could automate the regenerate-diff-patch workflow to some degree. Another solution could be to invoke the lemmas directly in Sail (\eg in special comments); this would solve the problem if there was no other reason to modify the \usail model, which could become a reasonable expectation as the backend is polished.

\section{Improvements to Katamaran}

This work led to the identification of some bugs, inefficiencies and missing capabilities of the solver, that needed to be handled before the verification could proceed.

Katamaran's executor is itself verified to be correct, so naturally we didn't run into any soundness bug. However, there were some issues with the wrong error being reported in certain cases, regressions where previously working proofs generated errors after an improvement to the solver, and subtle mistakes in the generated \usail, stemming \eg from \usail's bitvector concatenation's arguments being reversed with respect to Sail's.

\section{Code size and compilation time}

\begin{table}[t]
  \centering
  \renewcommand\footnoterule{}
  \begin{tabular}{llr}
    \toprule
    Component                         & Files                           & Lines       \\
    \midrule
    Sail model {\small (without tests)}      & \file{msp430-ipe-sail/}         & \(1\,187\)  \\
    \usail model                    & \file{Base.v}, \file{Machine.v} & \(11\,236\) \\
    \midrule
    universal contract verification & \file{Contracts.v}              & 753         \\
    bootcode blocks verification    & \file{BlockVer/}                & 844         \\
    custom predicates               & \file{Sig.v}                    & 95          \\
    \midrule
    {\small
    \begin{tabular}{@{}l@{}}
      \normalsize Iris model \\
      \; (incl. soundness statements \\
      \quad of UC and symbolic executor)
    \end{tabular}}
    &
      \begin{tabular}{@{}l@{}}
        \file{IrisModel.v}, \file{IrisInstance.v}, \\
        \file{Model.v}, \file{LoopVerification.v}, \\
        \file{BlockVer/Verifier.v}
      \end{tabular}
    & 336 \\[2.75ex]
    end-to-end result & \file{Bootcode.v} & \(1\,011\) \\
    \bottomrule
  \end{tabular}
  \caption{Lines of code of various parts of the project, excluding whitespace and comments, as computed by the \texttt{cloc} utility.}
  \label{tab:cloc}
\end{table}

\Cref{tab:cloc} counts the number of significant lines of code of the main parts of the \msp verification. Some observations:
\begin{itemize}
\item Most of \texttt{Base.v} and \texttt{Machine.v} were initially generated and then updated as needed. The current version of \file{Base.v} differs\footnote{Counting with \texttt{diff -y -{}-suppress-common-lines <file-1> <file-2> | wc -l}.}
by 85 lines from one generated from the current version of the Sail specification, and the number rises to \(3\,228\) for \file{Machine.v}; note though that the latter includes changes in generated identifiers and comments.
\item A direct comparison with the size of the previous Katamaran case studies is difficult, as both the MinimalCaps and RISC-V PMP used handwritten \usail specifications, respectively \(1\,096\) and \(2\,025\) lines long. MinimalCaps also has a Sail model which is 571 lines long; from all this we could extrapolate that \msp's ISA is 0.5--2× the size of the simplified version of RISC-V PMP.

\item There are only 9 lines of non-trivial proofs in \file{Contracts.v} (with 2--3 tactics per line) and 3 in \file{BlockVer/}. More manual proofs were initially needed, but were then deleted after Katamaran was updated to solve the corresponding verification conditions automatically.

\item The core of the IPE implementation has 139 significant lines of code, plus around a dozen of changes to the rest of the specification.
\end{itemize}

Finally, \cref{tab:times} reports on the compilation/verification times.

\begin{table}[H]
  \centering
  \begin{tabular}{lr}
    \toprule
    Component & Time (s) \\
    \midrule
    \usail model & 67 \\
    universal contract verification & 316 \\
    bootcode blocks verification & 219 \\
    Iris model and end-to-end result & 248 \\
    \bottomrule
  \end{tabular}
  \caption{Compilation time of various parts of the project.}
  \label{tab:times}
\end{table}


% Base 23s
% Machine 44s
% Contracts 316
% Spec 15s
% Verifier 13
% bootcodeblocks 3m11s
% irismodel 4
% irisintance 9
% model 7
% loopverification 6
% bootcode 3m42


%  we found the general structure of the proof to carry over well from riscvpmp, so maybe framework could help
