\chapter{Introduction}

An \intro{Instruction Set Architecture}[ISA] \cite{ArmISA} defines the interface between a CPU's hardware and software. It specifies the semantics of the instructions, the available registers, how the memory is managed, etc. In addition to these functional aspects, the ISA can guarantee some \emph{security} properties, particularly when the hardware supports primitives for the development of secure software, such as \intro{Trusted Execution Environments}[TEEs] \cite{SGX} or capability pointers \cite{Watson2023}.

Such security properties convey the \emph{intention} of the designers, but are only valid insofar as the functional features of the ISA uphold them. For example the assertion ``protected locations cannot be accessed by untrusted code'' is meaningless if no permission checks are specified for the \asm{store} instruction.

As a matter of fact, it is common for specific hardware designs to break their ISA's guarantees due to microarchitectural attacks, which typically fall out of the scope of the ISA, but also for the ISA itself to be inconsistent with its own security properties, \ie to be vulnerable to architectural attacks \cite{Bognar2024}\cite{Fei2021}.

Identifying such inconsistencies is a hard problem. Security properties assert what the CPU does \emph{not} do in an \emph{arbitrary} (attacker-controlled) state, so the testing strategies that are suitable for functional properties are not applicable or don't give full assurance (\eg fuzzing) in this case.

% Such security guarantees are essentially a \emph{promise} by the hardware designers to the users, like the rest of the ISA. However, while it is possible to test whether or not the functional properties hold (\eg by executing one instruction and inspecting the registers), the same approach is not sufficient in the case of security properties. The root of the problem is that functional properties say what the CPU \emph{does} in a given state, while security properties assert what the CPU does \emph{not} do in an \emph{arbitrary} (attacker-controlled) state (e.g. the value stored at a protected location is never leaked to unprivileged code).


A promising answer comes from the field of formal methods. The gap between the functional and security aspects of the ISA can be bridged by means of a formal proof, thus eliminating in principle all vulnerabilities arising from ill-specified architectures. Such proofs, if developed manually, require a large time investment and are not robust to changes to the ISA. Fortunately, (semi-)automated verification is feasible in this space, as demostrated by tools like \intro{Katamaran} \cite{Huyghebaert2023}.

The objective of this thesis is to apply Katamaran to a real-world architecture (namely Texas Instruments' \msp microcontrollers), proving that its ISA properly ensures integrity and confidentiality of data in the presence of a simple memory protection mechanism.
